{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66339395-9392-4c30-aa75-ec8c4a1925bc",
   "metadata": {},
   "source": [
    "# No Propagation: Training Neural Network without Backpropagation\n",
    "\n",
    "Alright. It's been a few weeks since my last article. I'm sorry for taking a break. I want to say it was because I'm busy preparing for my masters, getting my registration and enrollment into the university settled. That would be the ideal reason to give right? \n",
    "\n",
    "But apparently that is not the case. This long pause between my article actually happens because I lost a little bit of my drives and my motivation. No, don't worry. It's not because I'm stressed, depressed, lonely, sad or anything like that. It happens because I've achieved something that I can only dream of when I started this journey. I've been in the national television.\n",
    "\n",
    "Yeah, apparently, last 2 weeks I've been given the opportunity to talk about my book (AI untuk Pemula) that I wrote with my colleagues. That sliver of fame suddenly cause me to think that I have achieved it all. I need to have a real break to convince myself that the journey is just beginning. So, here I am today, after a few weeks break, writing my next article on AI. And this time, I will cover a new paper that's been released last month, called **No Propagation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06266a6-7783-4a76-bbc0-2c38177e41fd",
   "metadata": {},
   "source": [
    "## As Usual, the Abstract\n",
    "\n",
    "```\n",
    "The canonical deep learning approach for learning requires computing a gradient term at each layer by back-propagating the error signal from the output towards each learnable parameter. Given the stacked structure of neural networks, where each layer builds on the representation of the layer below, this approach leads to hierarchical representations. More abstract features live on the top layers of the model, while features on lower layers are expected to be less abstract. In contrast to this, we introduce a new learning method named NoProp, which does not rely on either forward or backwards propagation. Instead, NoProp takes inspiration from diffusion and flow matching methods, where each layer independently learns to denoise a noisy target. We believe this work takes a first step towards introducing a new family of gradient-free learning methods, that does not learn hierarchical representations – at least not in the usual sense. NoProp needs to fix the representation at each layer beforehand to a noised version of the target, learning a local denoising process that can then be exploited at inference. We demonstrate the effectiveness of our method on MNIST, CIFAR-10,and CIFAR-100 image classification benchmarks. Our results show that NoProp is a viable learning algorithm which achieves superior accuracy, is easier to use and computationally more efficient compared to other existing back-propagation-free methods. By departing from the traditional gradient based learning paradigm, NoProp alters how credit assignment is done within the network, enabling more efficient distributed learning as well as potentially impacting other characteristics of the learning process.\n",
    "```\n",
    "\n",
    "Yeah, this paper actually introduce a very revolutionary ideas. For a very long time, since it's popularization by Geoffrey Hinton, Backpropagation has been the accepted standard and methods to train a neural network. Yeah, there's been some variations to it. For example, Backpropagation Through Time (BPTT) that is designed for neural network with hidden states/ sequential neural network. There are differences between this variations, but mostly the basic tenets are almost the same.\n",
    "\n",
    "The neural network layer that you stacked on top of each other will go backward from the error signal that they received through loss function and will propagated backwards through each layer. Each layer which consists of learnable parameter will be adjusted based on their contributions to the overall error.\n",
    "\n",
    "Sounds easy to understand right?\n",
    "\n",
    "But based on this paper, the backpropagation method actually introduces several issues during training of the neural network. Among them are:\n",
    "1. High computational overhead due to the gradient has to be carried over and stored during training. This is an issue in itself as I have unintentionally covered in my implementation of STDE paper.\n",
    "\n",
    "https://medium.com/@maercaestro/stde-stochastic-taylor-derivative-estimator-the-winning-neurips-2024-paper-from-singapore-79a7ccc3dbfc\n",
    "\n",
    "2. The second issue as mention in the paper is backpropagation is biologically implausible. This is a known issue. Something that has been try to resolved by Geoffrey Hinton himself. But he seems unable to resolved it. He knows that we as humans don't learn through backpropagation. So, he try to correct learning algorithms that try to mimics learning by neuron, but he seems unable to do so.\n",
    "\n",
    "3. Finally, the backpropagation happens in sequence. Meaning that you carry that error signal and that gradients from output layer to the input. But that sequential nature of it can cause issues and lead to forgetting. This has also prevent parallelism computation. So researchers have been actively trying to resolve this one.\n",
    "\n",
    "So, that's why this paper introduce **No Propagation**. A new method of training neural network without backpropagation. They're taking inspiration from diffusion methods where each layer try to find some ways to denoise a noisy target.\n",
    "\n",
    "How are they doing it exactly? It's someting that we will cover in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bc8fe-137e-4859-b6ba-8628018719fa",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "Alright, now we need to understand the methodology. There's a lot of mathematical equatons here to unpack and understand. But I don't think I will go in details what each equations are. What we will do is understand the high level concept of what actually they're doing to achieve this no propagation methodology. So, let's peel this off one by one\n",
    "\n",
    "### Understanding first what happens during backpropagation\n",
    "Alright, for now have maybe have a good grasp on what happen during backpropagation. We know we start backpropagation by using the loss function. We find the difference between our predicted output and the true output using whatever metrics of loss function that we use. And once we got the error value, the error value will be send back propagated through all the layers, carried over by the error gradient. During this backpropagation, all the learnable parameters (the weight and biases) will be updated.\n",
    "\n",
    "Alright, each parameter updates will be different based on the input and the output of our data. For example, if we're training our neural network on language. Maybe the network on the top right will be updated more if they're handling the structure/grammar of the language. And maybe the bottom part of the network will be updated more if they're trained on the context of the language.\n",
    "\n",
    "This is what the guy that invented the NoProp method call as latent trajectory. It means that the latent information during the training will have different trajectory and determine which part of the network will be updated. Do you see where this is going?\n",
    "\n",
    "This means that, it seems totally unnecessary for us to update the entire network for one latent trajectory. What we need to do is stochasticly pick the parts of the network that needs to be updated based on its latent trajectory. And this is where No Prop comes with their solution.\n",
    "\n",
    "\n",
    "### So, how might we start?\n",
    "First, we don't use the standard loss function as we normally do in backpropagation. Our training objective will be differewnt. We will use ELBO (Evidence Lower Bound) as our training objective. It is defined as below:\n",
    "\n",
    "\n",
    "$$\n",
    "\\log p(y \\mid x) \\geq \\mathbb{E}_{q(z \\mid x, y)}\\left[\\log p(z, y \\mid x) - \\log q(z \\mid x, y)\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "ELBO is actually something that is used as loss function for variational autoencoders. In my last autoencoder deep explainer, we saw that normal autoencoders has issues in the sense that their latent space is not structured.. Meaning, the latent space has categorical overlap between each other (entangle between each other). For the same input and output, it maybe has separate network structure that handles the specific context of the training.\n",
    "\n",
    "However, when changed to different input and output, there will be different part of latent space/or network structure that handles specific context. The solution comes from the variational autoencoder (VAEs) that used ELBO as their loss function and training objectives.\n",
    "\n",
    "You may read more about my AE deep explainer here.\n",
    "https://medium.com/@maercaestro/understanding-autoencoder-part-2-navigating-the-tesseract-128b0ee39311\n",
    "\n",
    "So, what does ELBO do in essence?\n",
    "Say, if we want to model the probability of seeing some data x, x maybe an image, sound or text.\n",
    "\n",
    "$$\n",
    "p(x)\n",
    "$$\n",
    "\n",
    "But, your model has some latent variables, something that you cannot observe. For example the amount of 'cuteness' in that image. We can call that z. With z available, your model becomes incomplete. You can't possibly model z without x, and you can't possible model x without z. In mathematics, the best way to solve this is to integrate all possible hidden states of z to model all possible form of x. \n",
    "\n",
    "$$\n",
    "p(x) = \\int p(x, z) \\, dz\n",
    "$$\n",
    "\n",
    "\n",
    "But this is impossible to solve as because it will be too high dimensional (has toooo many factors to account for) and it has no closed forms.\n",
    "\n",
    "So, to solve this, we use a helper distribution q(z|x). We find the distribution of our latent variables to help us approximate p(x). \n",
    "We can first write it as below:\n",
    "\n",
    "\n",
    "$$\n",
    "\\log p(x) = \\log \\int p(x, z) \\, dz\n",
    "$$\n",
    "\n",
    "then we add the distriubtion of z into our integral\n",
    "\n",
    "$$\n",
    "\\log p(x) = \\log \\int q(z) \\frac{p(x, z)}{q(z)} \\, dz\n",
    "$$\n",
    "\n",
    "\n",
    "by using Jensen's Inequality (which is something that I need to understand in detail), the  equation will gives us a lower bound.\n",
    "\n",
    "\n",
    "$$\n",
    "\\log p(x) \\geq \\mathbb{E}_{q(z \\mid x)}\\left[ \\log \\frac{p(x, z)}{q(z \\mid x)} \\right]\n",
    "$$\n",
    "\n",
    "That right hand side is what we called as Evidence Lower Bound.\n",
    "\n",
    "To use it in our training, we can write it as below:\n",
    "\n",
    "$$\n",
    "\\text{ELBO} = \\mathbb{E}_{q(z \\mid x)}\\left[ \\log p(x, z) - \\log q(z \\mid x) \\right]\n",
    "$$\n",
    "\n",
    "It is a function of:\n",
    "\n",
    "* Your **generative model** $p(x, z)$\n",
    "* Your **inference model** $q(z \\mid x)$\n",
    "\n",
    "And we try to maximize it to make our model better.\n",
    "\n",
    "By doing this, we can model x and include all the latent variables and the hidden states inside it. This is how we achieve the latent trajectory that we intended when we train our model using NoProp.\n",
    "\n",
    "\n",
    "\n",
    "## And then what?\n",
    "Alright, now we know our loss function. Our training objectives. What we want next is to use it for our training. \n",
    "So, basically, in NoProp, instead of just ensuring that we can predict the ground truth as close as possbile, we also wants to the model to learn the meaningful sequence of hidden/latent variables which represent the internal hidden states (or trajectory) that the model uses to arrive at the prediction.\n",
    "\n",
    "So to explain all the latent variables, use all our layers inside our network and make them our z. So all the hideen states now will be identified as z.\n",
    "\n",
    "To better illustrate it,\n",
    "\n",
    "```lua\n",
    "x → z_0 → z_1 → ... → z_T → output\n",
    "```\n",
    "\n",
    "All the z will be sampled using the equation below\n",
    "\n",
    "$$\n",
    "z_t = a_t \\hat{u}_{\\theta_t}(z_{t-1}, x) + b_t z_{t-1} + \\sqrt{c_t} \\cdot \\epsilon_t\n",
    "\\quad \\text{where } \\epsilon_t \\sim \\mathcal{N}(0, I)\n",
    "$$\n",
    "\n",
    "\n",
    "There's three main components here that I can explain in detail as below\n",
    "\n",
    "1. ${u}_{\\theta_t}(z_{t-1},x)$  - a mini neural block that transforms the previous hidden states and input\n",
    "2. $a_t$ and $b_t$ is the learnable parameters\n",
    "3. $\\sqrt{c_t} \\cdot \\epsilon_t$ - the random noise that is introduce during sampling\n",
    "\n",
    "This z sampling will be done for both the forward (z_t) and the reverse mode (z_(t-1)).\n",
    "\n",
    "Once we have sample all the layers, until the end layers, we will use that to predict our y.\n",
    "\n",
    "And from there, we will use ELBO to find the loss of our prediction. And here comes the novel part.\n",
    "\n",
    "\n",
    "## The Novel Part\n",
    "\n",
    "The novel part here is that, we're actually using a modified ELBO as our loss function.\n",
    "Still remember our ELBO equation?\n",
    "\n",
    "$$\n",
    "\\text{ELBO} = \\mathbb{E}_{q(z \\mid x)}\\left[ \\log p(x, z) - \\log q(z \\mid x) \\right]\n",
    "$$\n",
    "\n",
    "It is a function of:\n",
    "\n",
    "* Your **generative model** $p(x, z)$\n",
    "* Your **inference model** $q(z \\mid x)$\n",
    "\n",
    "\n",
    "In No-Prop paper, we write ELBO as below\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{NoProp}} =\n",
    "\\mathbb{E}_{q(z_T \\mid y)}\\left[-\\log \\hat{p}_{\\theta_{\\text{out}}}(y \\mid z_T)\\right]\n",
    "+ D_{\\text{KL}}\\left(q(z_0 \\mid y) \\| p(z_0)\\right)\n",
    "+ \\frac{T}{2} \\, \\eta \\, \\mathbb{E}_{t \\sim \\mathcal{U}\\{1, T\\}} \\left[\n",
    "\\left(\\text{SNR}(t) - \\text{SNR}(t-1)\\right)\n",
    "\\left\\| \\hat{u}_{\\theta_t}(z_{t-1}, x) - u_y \\right\\|^2\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "So, there's three main parts here\n",
    "\n",
    "1. $\\mathbb{E}_{q(z_T \\mid y)}\\left[-\\log \\hat{p}_{\\theta_{\\text{out}}}(y \\mid z_T)\\right]$ - the standard cross entropy loss\n",
    "2. $D_{\\text{KL}}\\left(q(z_0 \\mid y) \\| p(z_0)\\right)$ - the KL divergence. This is actually the regularizer.\n",
    "3. $\\frac{T}{2} \\cdot \\eta \\cdot \\mathbb{E}_{t \\sim \\mathcal{U}\\{1, T\\}} \\left[(\\text{SNR}(t) - \\text{SNR}(t-1)) \\cdot\\left\\| \\hat{u}_{\\theta_t}(z_{t-1}, x) - u_y \\right\\|^2\\right]$ - make each block learns class structure.\n",
    "\n",
    "\n",
    "## In Summary\n",
    "Alright, tooo much mathematics. My head is spinning already. But what can we here is that, we simplify this into a simple flow, as below\n",
    "\n",
    "```\n",
    "Label y\n",
    "   │\n",
    "   ▼\n",
    "Sample z_T ~ q(z_T | y)\n",
    "   ↓\n",
    "Sample z_{T-1}, ..., z_0 ~ q(· | z_{t+1})      ← reverse path\n",
    "   ↓\n",
    "Forward z_0 → z_1 → ... → z_T using p(z_t | z_{t-1}, x)     ← generative model\n",
    "   ↓\n",
    "Predict ŷ from z_T\n",
    "   ↓\n",
    "Compute NoProp loss (ELBO):\n",
    "   - Cross-entropy (from output)\n",
    "   - KL divergence (z_0)\n",
    "   - L2 loss per block\n",
    "   ↓\n",
    "Update weights locally\n",
    "```\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
